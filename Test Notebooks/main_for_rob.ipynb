{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KaihuaTang/CiiV-Adversarial-Robustness.pytorch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZINDksFSn4y",
        "outputId": "a04ae9e3-f3e8-4db6-8cd0-23a782d14884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CiiV-Adversarial-Robustness.pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/CiiV-Adversarial-Robustness.pytorch/attacker\")\n",
        "sys.path.append(\"/content/CiiV-Adversarial-Robustness.pytorch/utils/attack_utils.py\")\n",
        "sys.path.append(\"/content/CiiV-Adversarial-Robustness.pytorch/utils/checkpoint_utils.py\")\n",
        "sys.path.append(\"/content/CiiV-Adversarial-Robustness.pytorch/utils/general_utils.py\")\n",
        "sys.path.append(\"/content/CiiV-Adversarial-Robustness.pytorch/utils/logger_utils.py\")\n",
        "sys.path.append(\"/content/CiiV-Adversarial-Robustness.pytorch/utils/train_utils.py\")"
      ],
      "metadata": {
        "id": "WSTaJCZSXc8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CiiV-Adversarial-Robustness.pytorch/"
      ],
      "metadata": {
        "id": "APBkP4BhTDC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_norm(images, config):\n",
        "    mean = [0.4914, 0.4822, 0.4465]\n",
        "    std = [0.2471, 0.2435, 0.2616]\n",
        "    mean = torch.tensor(mean).view(1,3,1,1).to(images.device)\n",
        "    std = torch.tensor(std).view(1,3,1,1).to(images.device)\n",
        "    images = (images - mean) / std\n",
        "    return images"
      ],
      "metadata": {
        "id": "WttmtpbeSZ6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Base_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    base model used for adversarial attack and defense\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Base_Model, self).__init__()\n",
        "        # attacking mode, i.e., generating attacking images\n",
        "        self.attacking = False\n",
        "\n",
        "    def set_attack(self):\n",
        "        self.attacking = True\n",
        "        # recursive set all modules to attack\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Base_Model) and (not m.is_attack()):\n",
        "                m.set_attack()\n",
        "\n",
        "    def set_unattack(self):\n",
        "        self.attacking = False\n",
        "        # recursive set all modules to unattack\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Base_Model) and m.is_attack():\n",
        "                m.set_unattack()\n",
        "\n",
        "    def is_attack(self):\n",
        "        return self.attacking"
      ],
      "metadata": {
        "id": "T7CF64UtTAsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffRl2dkzRKY0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "'''Pre-activation ResNet in PyTorch.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n",
        "'''\n",
        "\n",
        "# from models.Base_Model import Base_Model\n",
        "\n",
        "# from utils.train_utils import *\n",
        "\n",
        "class PreActBlock(Base_Model):\n",
        "    '''Pre-activation version of the BasicBlock.'''\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, activation='ReLU', softplus_beta=1):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes, track_running_stats=True, affine=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, track_running_stats=True, affine=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "        if activation == 'ReLU':\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "            print('ReLU')\n",
        "        elif activation == 'Softplus':\n",
        "            self.relu = nn.Softplus(beta=softplus_beta, threshold=20)\n",
        "            print('Softplus')\n",
        "        elif activation == 'GELU':\n",
        "            self.relu = nn.GELU()\n",
        "            print('GELU')\n",
        "        elif activation == 'ELU':\n",
        "            self.relu = nn.ELU(alpha=1.0, inplace=True)\n",
        "            print('ELU')\n",
        "        elif activation == 'LeakyReLU':\n",
        "            self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
        "            print('LeakyReLU')\n",
        "        elif activation == 'SELU':\n",
        "            self.relu = nn.SELU(inplace=True)\n",
        "            print('SELU')\n",
        "        elif activation == 'CELU':\n",
        "            self.relu = nn.CELU(alpha=1.2, inplace=True)\n",
        "            print('CELU')\n",
        "        elif activation == 'Tanh':\n",
        "            self.relu = nn.Tanh()\n",
        "            print('Tanh')\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(self.relu(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class PreActBottleneck(Base_Model):\n",
        "    '''Pre-activation version of the original Bottleneck module.'''\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, activation='ReLU', softplus_beta=1):\n",
        "        super(PreActBottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes, track_running_stats=True, affine=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, track_running_stats=True, affine=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes, track_running_stats=True, affine=True)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out = self.conv3(F.relu(self.bn3(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class PreActResNet(Base_Model):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, activation='ReLU', softplus_beta=1,\n",
        "                    num_sample=3, aug_weight=0.9, mask_center=[5, 16, 27]):\n",
        "        super(PreActResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.activation = activation\n",
        "        self.softplus_beta = softplus_beta\n",
        "\n",
        "        self.num_sample = num_sample\n",
        "        self.aug_weight = aug_weight\n",
        "        self.mask_center = mask_center\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.bn = nn.BatchNorm2d(512 * block.expansion, track_running_stats=True, affine=True)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "        if activation == 'ReLU':\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "            print('ReLU')\n",
        "        elif activation == 'Softplus':\n",
        "            self.relu = nn.Softplus(beta=softplus_beta, threshold=20)\n",
        "            print('Softplus')\n",
        "        elif activation == 'GELU':\n",
        "            self.relu = nn.GELU()\n",
        "            print('GELU')\n",
        "        elif activation == 'ELU':\n",
        "            self.relu = nn.ELU(alpha=1.0, inplace=True)\n",
        "            print('ELU')\n",
        "        elif activation == 'LeakyReLU':\n",
        "            self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
        "            print('LeakyReLU')\n",
        "        elif activation == 'SELU':\n",
        "            self.relu = nn.SELU(inplace=True)\n",
        "            print('SELU')\n",
        "        elif activation == 'CELU':\n",
        "            self.relu = nn.CELU(alpha=1.2, inplace=True)\n",
        "            print('CELU')\n",
        "        elif activation == 'Tanh':\n",
        "            self.relu = nn.Tanh()\n",
        "            print('Tanh')\n",
        "        print('Use activation of ' + activation)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride,\n",
        "                activation=self.activation, softplus_beta=self.softplus_beta))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def create_mask(self, w, h, center_x, center_y, alpha=10.0):\n",
        "        widths = torch.arange(w).view(1, -1).repeat(h,1)\n",
        "        heights = torch.arange(h).view(-1, 1).repeat(1,w)\n",
        "        mask = ((widths - center_x)**2 + (heights - center_y)**2).float().sqrt()\n",
        "        # non-linear\n",
        "        mask = (mask.max() - mask + alpha) ** 0.3\n",
        "        mask = mask / mask.max()\n",
        "        # sampling\n",
        "        mask = (mask + mask.clone().uniform_(0, 1)) > 0.9\n",
        "        mask.float()\n",
        "        return mask.unsqueeze(0)\n",
        "\n",
        "    def create_mask_candidate1(self, w, h, center_x, center_y, alpha=10.0):\n",
        "        widths = torch.arange(w).view(1, -1).repeat(h,1)\n",
        "        heights = torch.arange(h).view(-1, 1).repeat(1,w)\n",
        "        mask = ((widths - center_x)**2 + (heights - center_y)**2).float().sqrt()\n",
        "        # non-linear\n",
        "        mask = 1.0 - mask / 120\n",
        "        # sampling\n",
        "        mask = (mask + mask.clone().uniform_(0, 1)) > 0.9\n",
        "        mask.float()\n",
        "        return mask.unsqueeze(0)\n",
        "\n",
        "    def create_mask_candidate2(self, w, h, center_x, center_y, alpha=10.0):\n",
        "        widths = torch.arange(w).view(1, -1).repeat(h,1)\n",
        "        heights = torch.arange(h).view(-1, 1).repeat(1,w)\n",
        "        mask = ((widths - center_x)**2 + (heights - center_y)**2).float().sqrt()\n",
        "        # non-linear\n",
        "        mask = 2.5 / (0.6 * mask**0.5)\n",
        "        # sampling\n",
        "        mask = (mask + mask.clone().uniform_(0, 1)) > 0.9\n",
        "        mask.float()\n",
        "        return mask.unsqueeze(0)\n",
        "\n",
        "    def ciiv_forward(self, x, loop):\n",
        "        b, c, w, h = x.shape\n",
        "        samples = []\n",
        "        masks = []\n",
        "        NUM_LOOP = loop\n",
        "        NUM_INNER_SAMPLE = self.num_sample\n",
        "        NUM_TOTAL_SAMPLE = NUM_LOOP * NUM_INNER_SAMPLE\n",
        "\n",
        "        # generate all samples\n",
        "        for i in range(NUM_TOTAL_SAMPLE):\n",
        "            # differentiable sampling\n",
        "            sample = self.relu(x + x.detach().clone().uniform_(-1,1) * self.aug_weight)\n",
        "            sample = sample / (sample + 1e-5)\n",
        "            #on_sample = torch.clamp(x + torch.randn_like(x) * 0.1, min=0, max=1)\n",
        "            if i % NUM_INNER_SAMPLE == 0:\n",
        "                idx = int(i // NUM_INNER_SAMPLE)\n",
        "                x_idx = int(idx // 3)\n",
        "                y_idx = int(idx % 3)\n",
        "                center_x = self.mask_center[x_idx]\n",
        "                center_y = self.mask_center[y_idx]\n",
        "            # attention\n",
        "            mask = self.create_mask(w, h, center_x, center_y, alpha=10.0).to(x.device)\n",
        "            sample = sample * mask\n",
        "            samples.append(sample)\n",
        "            masks.append(mask)\n",
        "\n",
        "        # run network\n",
        "        outputs = []\n",
        "        features = []\n",
        "        z_scores = []\n",
        "        for i in range(NUM_LOOP):\n",
        "            # Normalized input\n",
        "            inputs = sum(samples[NUM_INNER_SAMPLE * i : NUM_INNER_SAMPLE * (i+1)]) / NUM_INNER_SAMPLE\n",
        "            z_score = (sum(masks[NUM_INNER_SAMPLE * i : NUM_INNER_SAMPLE * (i+1)]).float() / NUM_INNER_SAMPLE).mean()\n",
        "            # forward modules\n",
        "            out = self.conv1(inputs)\n",
        "            out = self.layer1(out)\n",
        "            out = self.layer2(out)\n",
        "            out = self.layer3(out)\n",
        "            out = self.layer4(out)\n",
        "            out = self.relu(self.bn(out))\n",
        "            size = out.shape[-1]\n",
        "            out = F.avg_pool2d(out, size)\n",
        "            feats = out.view(out.size(0), -1)\n",
        "            preds = self.linear(feats)\n",
        "            z_scores.append(z_score.view(1,1).repeat(b, 1))\n",
        "            features.append(feats)\n",
        "            outputs.append(preds)\n",
        "\n",
        "        final_pred = sum([pred / (z + 1e-9) for pred, z in zip(outputs, z_scores)]) / NUM_LOOP\n",
        "\n",
        "        ## Randomized Smoothing Inference\n",
        "        #if self.training or self.is_attack():\n",
        "        #    final_pred = sum([pred / (z + 1e-9) for pred, z in zip(outputs, z_scores)]) / NUM_LOOP\n",
        "        #else:\n",
        "        #    counts = []\n",
        "        #    for item in outputs:\n",
        "        #        pred = item.max(-1)[1]\n",
        "        #        counts.append(F.one_hot(pred, self.num_classes))\n",
        "        #    final_pred = sum(counts)\n",
        "        return final_pred, z_scores, features, outputs\n",
        "\n",
        "\n",
        "    def forward(self, x, loop=1):\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.repeat(1, 3, 1, 1)\n",
        "        # config is passed through main\n",
        "        x = rgb_norm(x, self.config)\n",
        "\n",
        "        if self.training:\n",
        "            return self.ciiv_forward(x, loop=loop)\n",
        "        else:\n",
        "            return self.ciiv_forward(x, loop=loop)[0]\n",
        "\n",
        "\n",
        "def PreActResNet18(num_classes=10, activation='ReLU', softplus_beta=1, **kwargs):\n",
        "    return PreActResNet(PreActBlock, [2,2,2,2], num_classes=num_classes, activation=activation, softplus_beta=softplus_beta, **kwargs)\n",
        "\n",
        "def PreActResNet34(num_classes, **kwargs):\n",
        "    return PreActResNet(PreActBlock, [3,4,6,3], num_classes, **kwargs)\n",
        "\n",
        "def PreActResNet50(num_classes, **kwargs):\n",
        "    return PreActResNet(PreActBottleneck, [3,4,6,3], num_classes, **kwargs)\n",
        "\n",
        "\n",
        "def create_model(m_type='resnet18', num_classes=1000, num_sample=3, aug_weight=0.9, mask_center=[5, 16, 27]):\n",
        "    # create various resnet models\n",
        "    if m_type == 'resnet18':\n",
        "        model = PreActResNet18(num_classes=num_classes, num_sample=num_sample,\n",
        "                                aug_weight=aug_weight, mask_center=mask_center)\n",
        "    elif m_type == 'resnet50':\n",
        "        model = PreActResNet50(num_classes=num_classes, num_sample=num_sample,\n",
        "                                aug_weight=aug_weight, mask_center=mask_center)\n",
        "    else:\n",
        "        raise ValueError('Wrong Model Type')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import importlib\n",
        "import random\n",
        "import attacker\n",
        "\n",
        "def rand_adv_init(config):\n",
        "    if random.uniform(0, 1) < config['attacker_opt']['attack_rand_ini']:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def create_adversarial_attacker(config, model, logger):\n",
        "    if config['attacker_opt']['attack_type'] == 'PGD':\n",
        "        return attacker.PGD(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'PGDL2':\n",
        "        return attacker.PGDL2(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'AutoAttack':\n",
        "        return attacker.AA(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                norm=config['attacker_opt']['attack_norm'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'FGSM':\n",
        "        return attacker.FGSM(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'FFGSM':\n",
        "        return attacker.FFGSM(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'GN':\n",
        "        return attacker.GN(model, logger, config, sigma=config['attacker_opt']['gn_sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'UN':\n",
        "        return attacker.UN(model, logger, config, sigma=config['attacker_opt']['un_sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'BPDAPGD':\n",
        "        return attacker.BPDAPGD(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'EOT':\n",
        "        return attacker.EOT(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                learning_rate=config['attacker_opt']['attack_lr'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'CW':\n",
        "        return attacker.CW(model, logger, config, c=config['attacker_opt']['c'],\n",
        "                                                kappa=config['attacker_opt']['kappa'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                                lr=config['attacker_opt']['lr'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'BFS':\n",
        "        return attacker.BFS(model, logger, config, sigma=config['attacker_opt']['sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'SPSA':\n",
        "        return attacker.SPSA(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                delta=config['attacker_opt']['delta'],\n",
        "                                                batch_size=config['attacker_opt']['batch_size'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                                lr=config['attacker_opt']['lr'],\n",
        "                                            )\n",
        "    else:\n",
        "        logger.raise_error('Wrong Attacker Type')\n",
        "\n",
        "\n",
        "\n",
        "def get_adv_target(target_type, model, inputs, gt_label):\n",
        "    with torch.no_grad():\n",
        "        preds = model(inputs).softmax(-1)\n",
        "    num_batch, num_class = preds.shape\n",
        "\n",
        "    if target_type == 'random':\n",
        "        adv_targets = torch.randint(0, num_class, (num_batch,)).to(gt_label.device)\n",
        "        # validation check\n",
        "        adv_targets = adv_target_update(gt_label, adv_targets, num_batch, num_class)\n",
        "    elif target_type == 'most':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = -1\n",
        "        adv_targets = preds.max(-1)[1]\n",
        "    elif target_type == 'least':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = 100.0\n",
        "        adv_targets = preds.min(-1)[1]\n",
        "    else:\n",
        "        raise ValueError('Wrong Targeted Attack Type')\n",
        "\n",
        "    assert (adv_targets == gt_label).long().sum().item() == 0\n",
        "    return adv_targets\n",
        "\n",
        "def adv_target_update(gt_label, adv_target, num_batch, num_class):\n",
        "    for i in range(num_batch):\n",
        "        if int(gt_label[i]) == int(adv_target[i]):\n",
        "            adv_target[i] = (int(adv_target[i]) + random.randint(1, num_class-1)) % num_class\n",
        "    return adv_target"
      ],
      "metadata": {
        "id": "RX8xd-_xUhej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "net = torchvision.models.resnet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
      ],
      "metadata": {
        "id": "ko429wRxmrTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import importlib\n",
        "import random\n",
        "import attacker\n",
        "\n",
        "def rand_adv_init(config):\n",
        "    if random.uniform(0, 1) < config['attacker_opt']['attack_rand_ini']:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def create_adversarial_attacker(config, model, logger):\n",
        "    if config['attacker_opt']['attack_type'] == 'PGD':\n",
        "        return attacker.PGD(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'PGDL2':\n",
        "        return attacker.PGDL2(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'AutoAttack':\n",
        "        return attacker.AA(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                norm=config['attacker_opt']['attack_norm'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'FGSM':\n",
        "        return attacker.FGSM(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'FFGSM':\n",
        "        return attacker.FFGSM(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'GN':\n",
        "        return attacker.GN(model, logger, config, sigma=config['attacker_opt']['gn_sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'UN':\n",
        "        return attacker.UN(model, logger, config, sigma=config['attacker_opt']['un_sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'BPDAPGD':\n",
        "        return attacker.BPDAPGD(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'EOT':\n",
        "        return attacker.EOT(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                learning_rate=config['attacker_opt']['attack_lr'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'CW':\n",
        "        return attacker.CW(model, logger, config, c=config['attacker_opt']['c'],\n",
        "                                                kappa=config['attacker_opt']['kappa'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                                lr=config['attacker_opt']['lr'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'BFS':\n",
        "        return attacker.BFS(model, logger, config, sigma=config['attacker_opt']['sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'SPSA':\n",
        "        return attacker.SPSA(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                delta=config['attacker_opt']['delta'],\n",
        "                                                batch_size=config['attacker_opt']['batch_size'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                                lr=config['attacker_opt']['lr'],\n",
        "                                            )\n",
        "    else:\n",
        "        logger.raise_error('Wrong Attacker Type')\n",
        "\n",
        "\n",
        "\n",
        "def get_adv_target(target_type, model, inputs, gt_label):\n",
        "    with torch.no_grad():\n",
        "        preds = model(inputs).softmax(-1)\n",
        "    num_batch, num_class = preds.shape\n",
        "\n",
        "    if target_type == 'random':\n",
        "        adv_targets = torch.randint(0, num_class, (num_batch,)).to(gt_label.device)\n",
        "        # validation check\n",
        "        adv_targets = adv_target_update(gt_label, adv_targets, num_batch, num_class)\n",
        "    elif target_type == 'most':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = -1\n",
        "        adv_targets = preds.max(-1)[1]\n",
        "    elif target_type == 'least':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = 100.0\n",
        "        adv_targets = preds.min(-1)[1]\n",
        "    else:\n",
        "        raise ValueError('Wrong Targeted Attack Type')\n",
        "\n",
        "    assert (adv_targets == gt_label).long().sum().item() == 0\n",
        "    return adv_targets\n",
        "\n",
        "def adv_target_update(gt_label, adv_target, num_batch, num_class):\n",
        "    for i in range(num_batch):\n",
        "        if int(gt_label[i]) == int(adv_target[i]):\n",
        "            adv_target[i] = (int(adv_target[i]) + random.randint(1, num_class-1)) % num_class\n",
        "    return adv_target"
      ],
      "metadata": {
        "id": "PSXBo2MOq_Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import attacker\n",
        "\n",
        "# from utils.attack_utils import *\n",
        "\n",
        "class test_ciiv():\n",
        "    def __init__(self, args, config, logger, model, val=False):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.model = model\n",
        "\n",
        "        # init inst setting\n",
        "        self.init_inst_sample()\n",
        "\n",
        "        # initialize attacker\n",
        "        self.adv_test = self.config['attacker_opt']['adv_val']\n",
        "        if self.adv_test:\n",
        "            self.attacker = create_adversarial_attacker(config, model, logger)\n",
        "\n",
        "        # save test\n",
        "        self.test_save = True if config['test_opt']['save_data'] else False\n",
        "\n",
        "        # get dataloader\n",
        "        if val:\n",
        "            self.phase = 'val'\n",
        "            self.loader = testloader\n",
        "        else:\n",
        "            self.phase = 'test'\n",
        "            self.loader = testloader\n",
        "\n",
        "    def init_inst_sample(self):\n",
        "        self.logger.info('=====> Init Instrumental Sampling')\n",
        "        self.w_ce = self.config['inst_sample']['w_ce']\n",
        "        self.w_reg = self.config['inst_sample']['w_reg']\n",
        "        self.mul_ru = self.config['inst_sample']['mul_ru']\n",
        "        self.num_loop = self.config['inst_sample']['num_loop']\n",
        "\n",
        "\n",
        "    def run_val(self, epoch):\n",
        "        self.logger.info('------------- Start Validation at Epoch {} -----------'.format(epoch))\n",
        "        total_acc = []\n",
        "\n",
        "        # set model to evaluation\n",
        "        self.model.eval()\n",
        "\n",
        "        # save test\n",
        "        if self.test_save:\n",
        "            org_list = []\n",
        "            adv_list = []\n",
        "            gt_list = []\n",
        "            pred_list = []\n",
        "\n",
        "        # run batch\n",
        "        for i, (inputs, labels, indexes) in enumerate(self.loader):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            batch_size = inputs.shape[0]\n",
        "            # print test time\n",
        "            # trigger adversarial attack or not\n",
        "            if self.adv_test:\n",
        "                if self.config['targeted_attack']:\n",
        "                    adv_targets = get_adv_target(self.config['targeted_type'], self.model, inputs, labels)\n",
        "                    adv_inputs = self.attacker.get_adv_images(inputs, adv_targets, random_start=rand_adv_init(self.config), targeted=True)\n",
        "                else:\n",
        "                    adv_inputs = self.attacker.get_adv_images(inputs, labels, random_start=rand_adv_init(self.config))\n",
        "                self.model.eval()\n",
        "                final_inputs = adv_inputs\n",
        "            else:\n",
        "                final_inputs = inputs\n",
        "\n",
        "            # run model\n",
        "            with torch.no_grad():\n",
        "                predictions = self.model(final_inputs, loop=self.num_loop)\n",
        "\n",
        "            if isinstance(predictions, tuple):\n",
        "                predictions = predictions[0]\n",
        "\n",
        "            total_acc.append((predictions.max(1)[1] == labels).view(-1, 1))\n",
        "\n",
        "            # save adversarial images\n",
        "            if self.test_save and i < self.config['test_opt']['save_length']:\n",
        "                org_list.append(inputs.cpu())\n",
        "                gt_list.append(labels.cpu())\n",
        "                pred_list.append(predictions.max(1)[1].cpu())\n",
        "                if self.adv_test:\n",
        "                    adv_list.append(adv_inputs.cpu())\n",
        "\n",
        "        all_acc = torch.cat(total_acc, dim=0).float()\n",
        "        avg_acc = all_acc.mean().item()\n",
        "        self.logger.info('Epoch {:5d} Evaluation Complete ==> Total Accuracy : {:9.4f}, Number Samples : {:9d}'.format(epoch, avg_acc, all_acc.shape[0]))\n",
        "\n",
        "        # set back to training mode again\n",
        "        self.model.train()\n",
        "\n",
        "        # save adversarial images\n",
        "        if self.test_save:\n",
        "            file_name = os.path.join(self.config['output_dir'], self.config['test_opt']['file_name'])\n",
        "            adv_output = {\n",
        "                    'org_images' : torch.cat(org_list, 0),\n",
        "                    'gt_labels'  : torch.cat(gt_list, 0),\n",
        "                    'adv_images' : torch.cat(adv_list, 0) if self.adv_test else 0,\n",
        "                    'pred_labels': torch.cat(pred_list, 0),\n",
        "                    }\n",
        "            torch.save(adv_output, file_name)\n",
        "            self.logger.info('=====> Complete! Adversarial images have been saved to {}'.format(file_name))\n",
        "\n",
        "        return avg_acc"
      ],
      "metadata": {
        "id": "9ZPPODfZZv5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import importlib\n",
        "import random\n",
        "import attacker\n",
        "\n",
        "# from data.dataloader import get_loader\n",
        "\n",
        "def rand_adv_init(config):\n",
        "    if random.uniform(0, 1) < config['attacker_opt']['attack_rand_ini']:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def create_adversarial_attacker(config, model, logger):\n",
        "    if config['attacker_opt']['attack_type'] == 'PGD':\n",
        "        return attacker.PGD(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'PGDL2':\n",
        "        return attacker.PGDL2(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'AutoAttack':\n",
        "        return attacker.AA(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                norm=config['attacker_opt']['attack_norm'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'FGSM':\n",
        "        return attacker.FGSM(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'FFGSM':\n",
        "        return attacker.FFGSM(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'GN':\n",
        "        return attacker.GN(model, logger, config, sigma=config['attacker_opt']['gn_sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'UN':\n",
        "        return attacker.UN(model, logger, config, sigma=config['attacker_opt']['un_sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'BPDAPGD':\n",
        "        return attacker.BPDAPGD(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                alpha=config['attacker_opt']['attack_alpha'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'EOT':\n",
        "        return attacker.EOT(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                learning_rate=config['attacker_opt']['attack_lr'],\n",
        "                                                steps=config['attacker_opt']['attack_step'],\n",
        "                                                eot_iter=config['attacker_opt']['eot_iter'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'CW':\n",
        "        return attacker.CW(model, logger, config, c=config['attacker_opt']['c'],\n",
        "                                                kappa=config['attacker_opt']['kappa'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                                lr=config['attacker_opt']['lr'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'BFS':\n",
        "        return attacker.BFS(model, logger, config, sigma=config['attacker_opt']['sigma'],\n",
        "                                                eps=config['attacker_opt']['attack_eps'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                            )\n",
        "    elif config['attacker_opt']['attack_type'] == 'SPSA':\n",
        "        return attacker.SPSA(model, logger, config, eps=config['attacker_opt']['attack_eps'],\n",
        "                                                delta=config['attacker_opt']['delta'],\n",
        "                                                batch_size=config['attacker_opt']['batch_size'],\n",
        "                                                steps=config['attacker_opt']['steps'],\n",
        "                                                lr=config['attacker_opt']['lr'],\n",
        "                                            )\n",
        "    else:\n",
        "        logger.raise_error('Wrong Attacker Type')\n",
        "\n",
        "\n",
        "\n",
        "def get_adv_target(target_type, model, inputs, gt_label):\n",
        "    with torch.no_grad():\n",
        "        preds = model(inputs).softmax(-1)\n",
        "    num_batch, num_class = preds.shape\n",
        "\n",
        "    if target_type == 'random':\n",
        "        adv_targets = torch.randint(0, num_class, (num_batch,)).to(gt_label.device)\n",
        "        # validation check\n",
        "        adv_targets = adv_target_update(gt_label, adv_targets, num_batch, num_class)\n",
        "    elif target_type == 'most':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = -1\n",
        "        adv_targets = preds.max(-1)[1]\n",
        "    elif target_type == 'least':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = 100.0\n",
        "        adv_targets = preds.min(-1)[1]\n",
        "    else:\n",
        "        raise ValueError('Wrong Targeted Attack Type')\n",
        "\n",
        "    assert (adv_targets == gt_label).long().sum().item() == 0\n",
        "    return adv_targets\n",
        "\n",
        "def adv_target_update(gt_label, adv_target, num_batch, num_class):\n",
        "    for i in range(num_batch):\n",
        "        if int(gt_label[i]) == int(adv_target[i]):\n",
        "            adv_target[i] = (int(adv_target[i]) + random.randint(1, num_class-1)) % num_class\n",
        "    return adv_target"
      ],
      "metadata": {
        "id": "g6Qanz6VrOTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import random\n",
        "import attacker\n",
        "\n",
        "# from test_baseline import test_baseline\n",
        "# from test_ciiv import test_ciiv\n",
        "\n",
        "def get_test_func(config):\n",
        "    # choosing test strategy\n",
        "    if config['strategy']['test_type'] == 'baseline':\n",
        "        test_func = test_baseline\n",
        "    elif config['strategy']['test_type'] == 'ciiv':\n",
        "        test_func = test_ciiv\n",
        "    else:\n",
        "        raise ValueError('Wrong Test Strategy')\n",
        "    return test_func\n",
        "\n",
        "\n",
        "\n",
        "def get_adv_target(target_type, model, inputs, gt_label):\n",
        "    with torch.no_grad():\n",
        "        preds = model(inputs).softmax(-1)\n",
        "    num_batch, num_class = preds.shape\n",
        "\n",
        "    if target_type == 'random':\n",
        "        adv_targets = torch.randint(0, num_class, (num_batch,)).to(gt_label.device)\n",
        "        # validation check\n",
        "        adv_targets = adv_target_update(gt_label, adv_targets, num_batch, num_class)\n",
        "    elif target_type == 'most':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = -1\n",
        "        adv_targets = preds.max(-1)[1]\n",
        "    elif target_type == 'least':\n",
        "        idxs = torch.arange(num_batch).to(inputs.device)\n",
        "        preds[idxs, gt_label] = 100.0\n",
        "        adv_targets = preds.min(-1)[1]\n",
        "    else:\n",
        "        raise ValueError('Wrong Targeted Attack Type')\n",
        "\n",
        "    assert (adv_targets == gt_label).long().sum().item() == 0\n",
        "    return adv_targets\n",
        "\n",
        "def adv_target_update(gt_label, adv_target, num_batch, num_class):\n",
        "    for i in range(num_batch):\n",
        "        if int(gt_label[i]) == int(adv_target[i]):\n",
        "            adv_target[i] = (int(adv_target[i]) + random.randint(0, num_class-1)) % num_class\n",
        "    return adv_target"
      ],
      "metadata": {
        "id": "zwzudcu_Ut0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Checkpoint():\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.save_best = config['checkpoint_opt']['save_best']\n",
        "        self.best_epoch = -1\n",
        "        self.best_performance = -1\n",
        "        self.best_model_path = None\n",
        "\n",
        "\n",
        "    def save(self, model, epoch, logger, acc):\n",
        "        # update best model\n",
        "        model_name = 'epoch_{}_'.format(epoch) + self.config['checkpoint_opt']['checkpoint_name']\n",
        "        model_path = os.path.join(self.config['output_dir'], model_name)\n",
        "        if acc is not None:\n",
        "            if float(acc) > self.best_performance:\n",
        "                self.best_epoch = epoch\n",
        "                self.best_performance = float(acc)\n",
        "                self.best_model_path = model_path\n",
        "                self.save_current = True\n",
        "                logger.info('Best model is updated at epoch {} with accuracy {:9.3f} (Path: {})'.format(self.best_epoch, self.best_performance, self.best_model_path))\n",
        "            else:\n",
        "                self.save_current = False\n",
        "        else:\n",
        "            # if acc is None, the newest is always the best\n",
        "            self.best_epoch = epoch\n",
        "            self.best_model_path = model_path\n",
        "\n",
        "        # only save the best model or the last model\n",
        "        best_saving = (self.save_best and self.save_current)\n",
        "        # only save at certain steps, best epoch or the last epoch\n",
        "        if (not best_saving) and (epoch % self.config['checkpoint_opt']['checkpoint_step'] != 0) and (epoch < (self.config['training_opt']['num_epochs'] - 1)):\n",
        "            return\n",
        "\n",
        "        output = {\n",
        "            'state_dict': model.state_dict(),\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "\n",
        "        logger.info('Model at epoch {} is saved to {}'.format(epoch, model_path))\n",
        "        torch.save(output, model_path)\n",
        "        logger.info('Best model is at epoch {} with accuracy {:9.3f}'.format(self.best_epoch, self.best_performance))\n",
        "        self.save_best_model(logger)\n",
        "\n",
        "\n",
        "    def save_best_model(self, logger):\n",
        "        logger.info('Best model is at epoch {} with accuracy {:9.3f} (Path: {})'.format(self.best_epoch, self.best_performance, self.best_model_path))\n",
        "        with open(os.path.join(self.config['output_dir'], 'best_checkpoint'), 'w+') as f:\n",
        "            f.write(self.best_model_path + ' ' + str(self.best_epoch) + ' ' + str(self.best_performance) + '\\n')\n",
        "\n",
        "    def load(self, model, path, logger):\n",
        "        if path.split('.')[-1] != 'pth':\n",
        "            with open(os.path.join(path, 'best_checkpoint')) as f:\n",
        "                path = f[0].split(' ')[0]\n",
        "\n",
        "        checkpoint = torch.load(path, map_location='cpu')\n",
        "        logger.info('Loading checkpoint pretrained with epoch {}.'.format(checkpoint['epoch']))\n",
        "        model_state = checkpoint['state_dict']\n",
        "\n",
        "        x = model.state_dict()\n",
        "        for key, _ in x.items():\n",
        "            if key in model_state:\n",
        "                x[key] = model_state[key]\n",
        "                logger.info('Load {:>50} from checkpoint.'.format(key))\n",
        "            elif 'module.' + key in model_state:\n",
        "                x[key] = model_state['module.' + key]\n",
        "                logger.info('Load {:>50} from checkpoint (rematch with module.).'.format(key))\n",
        "            else:\n",
        "                logger.info('WARNING: Key {} is missing in the checkpoint.'.format(key))\n",
        "\n",
        "        model.load_state_dict(x)\n",
        "        pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JbJxb0KUrpAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# import utils.general_utils as utils\n",
        "# from data.dataloader import get_loader\n",
        "# from utils.checkpoint_utils import Checkpoint\n",
        "\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import attacker\n",
        "import numpy as np\n",
        "\n",
        "# from utils.attack_utils import *\n",
        "# from utils.train_utils import *\n",
        "# from utils.test_utils import *\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes=10):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.cls = classes\n",
        "\n",
        "    def forward(self, pred, target, confidence, dim=-1):\n",
        "        smoothing = 1.0 - confidence\n",
        "        pred = pred.log_softmax(dim=dim)\n",
        "        with torch.no_grad():\n",
        "            # true_dist = pred.data.clone()\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=dim))\n",
        "\n",
        "class train_ciiv():\n",
        "    def __init__(self, args, config, logger, model, eval=False):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.model = model\n",
        "        self.training_opt = config['training_opt']\n",
        "        self.checkpoint = Checkpoint(config)\n",
        "        self.logger.info('============= Training Strategy: CiiV Training ============')\n",
        "\n",
        "        # get dataloader\n",
        "        self.logger.info('=====> Get train dataloader')\n",
        "        self.train_loader = trainloader#get_loader(config, 'train', logger)\n",
        "\n",
        "        # init inst setting\n",
        "        self.init_inst_sample()\n",
        "\n",
        "        # create optimizer\n",
        "        self.create_optimizer()\n",
        "\n",
        "        # create scheduler\n",
        "        self.create_scheduler()\n",
        "\n",
        "        # create loss\n",
        "        self.creat_loss()\n",
        "\n",
        "        # adversarial train\n",
        "        self.adv_train = self.config['attacker_opt']['adv_train']\n",
        "        if self.adv_train:\n",
        "            self.attacker = create_adversarial_attacker(config, model, logger)\n",
        "\n",
        "        # set eval\n",
        "        if eval:\n",
        "            # choosing test strategy\n",
        "            test_func = get_test_func(config)\n",
        "            # start testing\n",
        "            self.testing = test_func(args, config, logger, model, val=True)\n",
        "\n",
        "    def init_inst_sample(self):\n",
        "        self.logger.info('=====> Init Instrumental Sampling')\n",
        "        self.w_ce = self.config['inst_sample']['w_ce']\n",
        "        self.w_reg = self.config['inst_sample']['w_reg']\n",
        "        self.mul_ru = self.config['inst_sample']['mul_ru']\n",
        "        self.num_loop = self.config['inst_sample']['num_loop']\n",
        "\n",
        "    def creat_loss(self):\n",
        "        if self.config['inst_sample']['ce_smooth']:\n",
        "            self.criterion = LabelSmoothingLoss(classes=self.config['networks']['params']['num_classes'])\n",
        "        else:\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def create_optimizer(self):\n",
        "        self.logger.info('=====> Create optimizer')\n",
        "        optim_params = self.training_opt['optim_params']\n",
        "        optim_params_dict = {'params': self.model.parameters(),\n",
        "                            'lr': optim_params['lr'],\n",
        "                            'momentum': optim_params['momentum'],\n",
        "                            'weight_decay': optim_params['weight_decay']\n",
        "                            }\n",
        "\n",
        "        if self.training_opt['optimizer'] == 'Adam':\n",
        "            self.optimizer = optim.Adam([optim_params_dict, ])\n",
        "        elif self.training_opt['optimizer'] == 'SGD':\n",
        "            self.optimizer = optim.SGD([optim_params_dict, ])\n",
        "        else:\n",
        "            self.logger.info('********** ERROR: unidentified optimizer **********')\n",
        "\n",
        "\n",
        "    def create_scheduler(self):\n",
        "        self.logger.info('=====> Create Scheduler')\n",
        "        scheduler_params = self.training_opt['scheduler_params']\n",
        "        if self.training_opt['scheduler'] == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, self.training_opt['num_epochs'], eta_min=scheduler_params['endlr'])\n",
        "        elif self.training_opt['scheduler'] == 'step':\n",
        "            self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, gamma=scheduler_params['gamma'], milestones=scheduler_params['milestones'])\n",
        "        else:\n",
        "            self.logger.info('********** ERROR: unidentified optimizer **********')\n",
        "\n",
        "    def l2_loss(self, x, y):\n",
        "        diff = x - y\n",
        "        diff = diff*diff\n",
        "        diff = diff.sum(1)\n",
        "        diff = diff.mean(0)\n",
        "        return diff\n",
        "\n",
        "    def smooth_l1_loss(self, x, y):\n",
        "        diff = F.smooth_l1_loss(x, y, reduction='none')\n",
        "        diff = diff.sum(1)\n",
        "        diff = diff.mean(0)\n",
        "        return diff\n",
        "\n",
        "    def get_mean_wo_i(self, inputs, i):\n",
        "        return (sum(inputs) - inputs[i]) / float(len(inputs) - 1)\n",
        "\n",
        "    def run(self):\n",
        "        # Start Training\n",
        "        self.logger.info('=====> Start Naive Training')\n",
        "\n",
        "        # run epoch\n",
        "        for epoch in range(self.training_opt['num_epochs']):\n",
        "            self.logger.info('------------ Start Epoch {} -----------'.format(epoch))\n",
        "            self.model.train()\n",
        "\n",
        "            # run batch\n",
        "            total_batch = len(self.train_loader)\n",
        "            for step, (inputs, labels, indexes) in enumerate(self.train_loader):\n",
        "                # naive training\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                if self.adv_train:\n",
        "                    final_inputs = self.attacker.get_adv_images(inputs, labels)\n",
        "                else:\n",
        "                    final_inputs = inputs\n",
        "\n",
        "                # instrumental sampling training by running all samples parallelly\n",
        "                iter_info_print = {}\n",
        "                all_ces = []\n",
        "                all_regs = []\n",
        "                preds, z_scores, features, logits = self.model(final_inputs, loop=self.num_loop)\n",
        "                for i, logit in enumerate(logits):\n",
        "                    if self.config['inst_sample']['ce_smooth']:\n",
        "                        ce_loss = self.criterion(logit, labels, confidence=float(z_scores[i]))\n",
        "                    else:\n",
        "                        ce_loss = self.criterion(logit, labels)\n",
        "                    iter_info_print['ce_loss_{}'.format(i)] = ce_loss.sum().item()\n",
        "                    all_ces.append(ce_loss)\n",
        "\n",
        "                for i in range(len(features)):\n",
        "                    if self.config['inst_sample']['reg_loss'] == 'L2':\n",
        "                        reg_loss = self.l2_loss(features[i] * self.get_mean_wo_i(z_scores, i), self.get_mean_wo_i(features, i) * z_scores[i])\n",
        "                        iter_info_print['ciiv_l2loss_{}'.format(i)] = reg_loss.sum().item()\n",
        "                    elif self.config['inst_sample']['reg_loss'] == 'L1':\n",
        "                        reg_loss = self.smooth_l1_loss(features[i] * self.get_mean_wo_i(z_scores, i), self.get_mean_wo_i(features, i) * z_scores[i])\n",
        "                        iter_info_print['ciiv_l1loss_{}'.format(i)] = reg_loss.sum().item()\n",
        "                    else:\n",
        "                        raise ValueError('Wrong Reg Loss Type')\n",
        "                    all_regs.append(reg_loss)\n",
        "\n",
        "                loss = self.w_ce * sum(all_ces) / len(all_ces) + self.w_reg * sum(all_regs) / len(all_regs)\n",
        "                iter_info_print['w_ce'] = self.w_ce\n",
        "                iter_info_print['w_reg'] = self.w_reg\n",
        "\n",
        "                # backward\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                # calculate accuracy\n",
        "                accuracy = (preds.max(1)[1] == labels).sum().float() / preds.shape[0]\n",
        "\n",
        "                # log information\n",
        "                iter_info_print.update( {'Accuracy' : accuracy.item(), 'Loss' : loss.sum().item(), 'Poke LR' : float(self.optimizer.param_groups[0]['lr'])} )\n",
        "                self.logger.info_iter(epoch, step, total_batch, iter_info_print, self.config['logger_opt']['print_iter'])\n",
        "                if self.config['logger_opt']['print_grad'] and step % 1000 == 0:\n",
        "                    utils.print_grad(self.model.named_parameters())\n",
        "\n",
        "            # evaluation on validation set\n",
        "            self.optimizer.zero_grad()\n",
        "            val_acc = self.testing.run_val(epoch)\n",
        "\n",
        "            # update regression loss weight for BPFC or Instrumental Sampling\n",
        "            if (epoch in self.config['inst_sample']['milestones']):\n",
        "                self.logger.info('update regression weight from {} to {}'.format(self.w_reg, self.w_reg * self.mul_ru))\n",
        "                self.w_reg = self.w_reg * self.mul_ru\n",
        "\n",
        "            # checkpoint\n",
        "            self.checkpoint.save(self.model, epoch, self.logger, acc=val_acc)\n",
        "            # update scheduler\n",
        "            self.scheduler.step()\n",
        "        # save best model path\n",
        "        self.checkpoint.save_best_model(self.logger)\n",
        "\n"
      ],
      "metadata": {
        "id": "yoZie0TFRkV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import importlib\n",
        "\n",
        "\n",
        "def update_attacker_info(config, attack_config, dataset_name, attacker_type, attacker_set):\n",
        "    print('==================== Attacker {} ================='.format(attacker_type))\n",
        "    config['attacker_opt']['attack_type'] = attacker_type\n",
        "    config['attacker_opt']['attack_set'] = attacker_set\n",
        "    config['attacker_opt'].update(attack_config[dataset_name][attacker_type][attacker_set])\n",
        "\n",
        "def RepresentsInt(s):\n",
        "    try:\n",
        "        int(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def RepresentsFloat(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def int_to_others(val):\n",
        "    if val == 'true' or val == 'True':\n",
        "        return True\n",
        "    elif val == 'false' or val == 'False':\n",
        "        return False\n",
        "    elif RepresentsInt(val):\n",
        "        return int(val)\n",
        "    elif RepresentsFloat(val):\n",
        "        return float(val)\n",
        "    else:\n",
        "        return val\n",
        "\n",
        "def update_config_key(update_dict, key, new_val):\n",
        "    names = key.split('.')\n",
        "    while(len(names) > 1):\n",
        "        item_key = names.pop(0)\n",
        "        update_dict = update_dict[item_key]\n",
        "    old_val = update_dict[names[-1]]\n",
        "    update_dict[names[-1]] = int_to_others(new_val)\n",
        "    return old_val\n",
        "\n",
        "def update(config, args, logger):\n",
        "    if args.output_dir is not None:\n",
        "        config['output_dir'] = args.output_dir\n",
        "        logger.info('======= Update Config: output_dir is set to : ' + str(config['output_dir']))\n",
        "    if args.train_type is not None:\n",
        "        config['strategy']['train_type'] = args.train_type\n",
        "        logger.info('======= Update Config: training type is set to: '.format(args.train_type))\n",
        "    if args.test_type is not None:\n",
        "        config['strategy']['test_type'] = args.test_type\n",
        "        logger.info('======= Update Config: test type is set to: '.format(args.test_type))\n",
        "    if args.adv_train:\n",
        "        config['attacker_opt']['adv_train'] = args.adv_train\n",
        "    if args.adv_test:\n",
        "        config['attacker_opt']['adv_val'] = args.adv_test\n",
        "    if args.adv_type is not None:\n",
        "        config['attacker_opt']['attack_type'] = args.adv_type\n",
        "    if args.adv_setting is not None:\n",
        "        config['attacker_opt']['attack_set'] = args.adv_setting\n",
        "    if args.rand_aug:\n",
        "        config['dataset']['rand_aug'] = True\n",
        "        logger.info('===================> Using Random Augmentation')\n",
        "\n",
        "    if args.target_type:\n",
        "        config['targeted_attack'] = True\n",
        "        config['targeted_type'] = args.target_type\n",
        "    else:\n",
        "        config['targeted_attack'] = False\n",
        "\n",
        "    # update config from command\n",
        "    if len(args.opts) > 0 and (len(args.opts) % 2) == 0:\n",
        "        for i in range(len(args.opts)//2):\n",
        "            key = args.opts[2*i]\n",
        "            val = args.opts[2*i+1]\n",
        "            old_val = update_config_key(config, key, val)\n",
        "            logger.info('=====> {}: {} (old key) => {} (new key)'.format(key, old_val, val))\n",
        "    return config\n",
        "\n",
        "def source_import(file_path):\n",
        "    \"\"\"This function imports python module directly from source code using importlib\"\"\"\n",
        "    spec = importlib.util.spec_from_file_location('', file_path)\n",
        "    module = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(module)\n",
        "    return module\n",
        "\n",
        "def print_grad(named_parameters):\n",
        "    \"\"\" show grads \"\"\"\n",
        "    total_norm = 0\n",
        "    param_to_norm = {}\n",
        "    param_to_shape = {}\n",
        "    for n, p in named_parameters:\n",
        "        if p.grad is not None:\n",
        "            param_norm = p.grad.data.norm(2)\n",
        "            total_norm += param_norm ** 2\n",
        "            param_to_norm[n] = param_norm\n",
        "            param_to_shape[n] = p.size()\n",
        "    total_norm = total_norm ** (1. / 2)\n",
        "    print('---Total norm {:.3f} -----------------'.format(total_norm))\n",
        "    for name, norm in sorted(param_to_norm.items(), key=lambda x: -x[1]):\n",
        "            print(\"{:<50s}: {:.3f}, ({})\".format(name, norm, param_to_shape[name]))\n",
        "    print('-------------------------------', flush=True)\n",
        "    return total_norm\n",
        "\n",
        "def print_config(config, logger, head=''):\n",
        "    for key, val in config.items():\n",
        "        if isinstance(val, dict):\n",
        "            logger.info(head + str(key))\n",
        "            print_config(val, logger, head=head + '   ')\n",
        "        else:\n",
        "            logger.info(head + '{} : {}'.format(str(key), str(val)))\n",
        "\n",
        "class TriggerAction():\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.action = {}\n",
        "\n",
        "    def add_action(self, name, func):\n",
        "        assert str(name) not in self.action\n",
        "        self.action[str(name)] = func\n",
        "\n",
        "    def remove_action(self, name):\n",
        "        assert str(name) in self.action\n",
        "        del self.action[str(name)]\n",
        "        assert str(name) not in self.action\n",
        "\n",
        "    def run_all(self, logger=None):\n",
        "        for key, func in self.action.items():\n",
        "            if logger:\n",
        "                logger.info('trigger {}'.format(key))\n",
        "            func()"
      ],
      "metadata": {
        "id": "i3ugKD8QRmEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = train_ciiv(args, config, logger, model, eval=args.require_eval)\n",
        "training.run()"
      ],
      "metadata": {
        "id": "f1hwEUsGnD21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normal test\n",
        "\n",
        "checkpoint = Checkpoint(config)\n",
        "checkpoint.load(model, args.load_dir, logger)\n",
        "# start testing\n",
        "test_func = get_test_func(config)\n",
        "if args.phase == 'val':\n",
        "    testing = test_func(args, config, logger, model, val=True)\n",
        "    testing.run_val(epoch=-1)\n",
        "elif args.phase == 'test':\n",
        "    testing = test_func(args, config, logger, model, val=False)\n",
        "    testing.run_val(epoch=-1)\n",
        "else:\n",
        "    raise ValueError('Wrong Phase')"
      ],
      "metadata": {
        "id": "VJRd0DTUsnUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}